{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Trees with the Titanic\n",
    "\n",
    "### Due 03/14/2016\n",
    "### By Jacob Metzger\n",
    "\n",
    "Goal: Create a best-attempt model for determining survival on the Titanic using Gradient Boosted Trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division #for floating division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "%matplotlib inline\n",
    "np.random.seed(314) # Set for reproducibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The following is clipped from the Random Forests == Awesome notebook in the course notes\n",
    "\n",
    "# Here is a simple function to show descriptive stats on the categorical variables\n",
    "def describe_categorical(X):\n",
    "    \"\"\"\n",
    "    Just like .describe(), but returns the results for\n",
    "    categorical variables only.\n",
    "    \"\"\"\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(X[X.columns[X.dtypes == \"object\"]].describe().to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Another function taken from the Random Forests == Awesome notebook from the course page\n",
    "\n",
    "# Look at all the columns in the dataset\n",
    "def printall(X, max_rows=10):\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(X.to_html(max_rows=max_rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing functions/options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Handle PassengerId\n",
    "def handlePassengerId(X):\n",
    "    return X #don't do anything\n",
    "\n",
    "def dropPassengerId(X):\n",
    "    return X.drop([\"PassengerId\"], axis=1) #Drop the PassengerId at the onset -- any value this variable has is elusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Handle Ticket\n",
    "def handleTicket(X): #Handles ticket by splitting the ticket number and ticket prefix, providing the number and a boolean variable instead\n",
    "    ticketsSplit = [_.split(\" \") for _ in X.Ticket] #split the ticket codes into prefix and number\n",
    "    ticketNumbers = [int(_[-1]) if _[-1]!='LINE' else 0 for _ in ticketsSplit] \n",
    "    ticketNumbersTransform = np.log(np.array(ticketNumbers)+1)\n",
    "    hasTicketPrefix = [1 if _.__len__()>1 else 0 for _ in ticketsSplit] \n",
    "    X = pd.concat([X, pd.DataFrame(ticketNumbersTransform, columns=['TicketNumTrans']), pd.DataFrame(hasTicketPrefix, columns=[\"HasTicketPrefix\"])], axis=1)\n",
    "    X=X.drop([\"Ticket\"], axis=1)\n",
    "    return X\n",
    "\n",
    "def dropTicket(X):\n",
    "    return X.drop([\"Ticket\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Handle Name\n",
    "def handleName(X): #Handles Name by taking the prefix, correcting for some odd values, and providing dummy variables\n",
    "    prefixes = [name.split(\",\")[1].split(\" \")[1] for name in X.Name]\n",
    "    for i, item in enumerate(prefixes):\n",
    "        if prefixes[i] in [\"Mr.\", \"Miss.\", \"Mrs.\", \"Master.\"]:\n",
    "            #do nothing\n",
    "            pass\n",
    "        elif prefixes[i] in [\"Mlle.\"]:\n",
    "            prefixes[i]=\"Miss.\"\n",
    "        elif prefixes[i] in [\"Ms.\", \"Mme.\"]:\n",
    "            prefixes[i]=\"Mrs.\"\n",
    "        elif prefixes[i] in [\"Jonkheer.\", \"Sir.\", \"Don.\"]:\n",
    "            prefixes[i] = \"Nobility\"\n",
    "        elif prefixes[i] in [\"Lady.\", \"the\"]: #\"the\" is for the countess\n",
    "            prefixes[i] = \"Nobility\"\n",
    "        elif prefixes[i] in [\"Col.\", \"Major.\", \"Capt.\"]:\n",
    "            prefixes[i]=\"CrewMember\"\n",
    "        elif prefixes[i] in [\"Dr.\", \"Rev.\"]:\n",
    "            prefixes[i]=\"CrewMember\"\n",
    "        else:\n",
    "            print item # There should be no output if all prefixes are handled correctly!\n",
    "    X = pd.concat([X, pd.get_dummies(prefixes)], axis=1)\n",
    "    X = X.drop([\"Name\"], axis=1)\n",
    "    return X\n",
    "\n",
    "def dropName(X):\n",
    "    return X.drop([\"Name\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Handle SibSp\n",
    "def handleSibSp(X): #Handles SibSp with a mathematical transform\n",
    "    X = pd.concat([X, pd.DataFrame([np.exp(-1/(x+1)**2) for x in X.SibSp], columns=[\"SibSpTransform\"])], axis=1)\n",
    "    X = X.drop(['SibSp'], axis=1)\n",
    "    return X\n",
    "\n",
    "def dropSibSp(X):\n",
    "    return X.drop([\"SibSp\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Handle Parch\n",
    "def handleParch(X): #Handles Parch with a mathematical transform\n",
    "    X = pd.concat([X, pd.DataFrame([np.exp(-1/(x+1)**2) for x in X.Parch], columns=[\"ParchTransform\"])], axis=1)\n",
    "    X = X.drop(['Parch'], axis=1)\n",
    "    return X\n",
    "\n",
    "def dropParch(X):\n",
    "    return X.drop(['Parch'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def haveFamily((x,y)):\n",
    "    if x>0 or y>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def addFamily(X):\n",
    "    X=pd.concat([X, pd.DataFrame(map(haveFamily, zip(X.Parch, X.SibSp)), columns=[\"Family\"])], axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Handle Cabin\n",
    "def handleCabin(X): #Handles cabin by providing both a cabin count (imputing a mean, when necessary) and the cabin letter\n",
    "    cabinSplit = [str(_).split(\" \") for _ in X.Cabin] #tokenize the cabins\n",
    "    cabinsFinalSplit = [[cabin if cabin==\"nan\" else [cabin[0],cabin[1:]] for cabin in cabins] for cabins in cabinSplit] \n",
    "\n",
    "    numCabins = [0 if _[0]==\"nan\" else _.__len__() for _ in cabinsFinalSplit ]\n",
    "    X = pd.concat([X, pd.DataFrame(numCabins, columns=[\"NumCabins\"])], axis=1)\n",
    "    X.NumCabins=X.NumCabins.replace(0, X.NumCabins.mean())\n",
    "\n",
    "    cabinLetters = [\"None\" if cabin[0]==\"nan\" else cabin[0][0] for cabin in cabinsFinalSplit]\n",
    "    X=pd.concat([X, pd.get_dummies(pd.DataFrame(cabinLetters, columns=[\"CabinLetters\"]))], axis=1)\n",
    "    X=X.drop([\"Cabin\"], axis=1)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def dropCabin(X):\n",
    "    return X.drop([\"Cabin\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Handle PClass\n",
    "def handlePclass(X): #Provides dummy variables for Pclass\n",
    "    X = pd.concat([X, pd.get_dummies(X.Pclass)], axis=1)\n",
    "    X = X.drop([\"Pclass\"], axis=1)\n",
    "    return X\n",
    "\n",
    "def dropPclass(X):\n",
    "    return X.drop([\"Pclass\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Handle Sex\n",
    "def handleSex(X): #Provides dummy variables for Sex\n",
    "    X.Sex = pd.get_dummies(X.Sex).female #Just replace the Sex column altogether\n",
    "    return X\n",
    "\n",
    "def dropSex(X):\n",
    "    return X.drop([\"Sex\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Handle Embarked\n",
    "def handleEmbarked(X): #Provides dummy variables for Embarked after imputing missing values with the mode\n",
    "    X.Embarked = X.Embarked.fillna(X.Embarked.mode())\n",
    "    X = pd.concat([X, pd.get_dummies(X.Embarked)], axis=1)\n",
    "    X = X.drop([\"Embarked\"], axis=1)\n",
    "    return X\n",
    "\n",
    "def dropEmbarked(X):\n",
    "    return X.drop([\"Embarked\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Handle Fare\n",
    "def handleFareBasic(X): #Handles Fare by imputing the mean into N/A and 0 values\n",
    "    originalFare = X.Fare\n",
    "    X.Fare = X.Fare.fillna(originalFare.mean())\n",
    "    X.Fare = X.Fare.replace(0, originalFare.mean()) #It seems odd to have zero fares... Probably outliers anyway, so impute them.\n",
    "    return X\n",
    "\n",
    "def handleFareAdvanced(X):\n",
    "    X_copy=X.copy()\n",
    "    fareDataset = meanAge(X_copy) \n",
    "    fareDataset.dropna(axis=0)\n",
    "    \n",
    "    fareTrainingSet = fareDataset[fareDataset.Fare!=0]\n",
    "    #print fareTrainingSet.Fare.min()\n",
    "    fareTarget = fareTrainingSet.pop(\"Fare\")\n",
    "    #print fareTarget.shape\n",
    "    #print fareTrainingSet.shape\n",
    "    \n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    fareRegressor = GradientBoostingRegressor(n_estimators=100)\n",
    "    fareRegressor.fit(fareTrainingSet, fareTarget)\n",
    "    \n",
    "    counter=0\n",
    "    for row in xrange(0,len(X_copy.Fare)):\n",
    "        if X.Fare[row]==0:\n",
    "            X.Fare[row]=fareRegressor.predict(X_copy.iloc[row].drop(\"Fare\").reshape(1,-1))\n",
    "            #print X.iloc[row]\n",
    "            counter+=1\n",
    "    return X\n",
    "    \n",
    "    \n",
    "def binFare(X): #Handles Fare by binning it into a set of bins\n",
    "    numFareBins = 10\n",
    "    fareBins = pd.cut(X.Fare, numFareBins, labels=[str(_)+\"Fare\" for _ in range(0, numFareBins, 1)])\n",
    "    X = pd.concat([X, pd.get_dummies(fareBins)], axis=1)\n",
    "    X = X.drop([\"Fare\"], axis=1)\n",
    "    return X\n",
    "    \n",
    "def logFare(X): #Handles Fare with a log transform\n",
    "    X.Fare = np.log(X.Fare+1)\n",
    "    return X\n",
    "    \n",
    "def dropFare(X):\n",
    "    return X.drop([\"Fare\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Handle Age\n",
    "def handleAge(X): #Fills missing values of Age with the predictions of a Random Forest regression on the other variables\n",
    "    ageDataset=X.dropna(axis=0)\n",
    "    ageTarget = pd.DataFrame(ageDataset.Age)\n",
    "    ageDataset = ageDataset.drop([\"Age\"], axis=1)\n",
    "\n",
    "    import numpy\n",
    "    datasetMissingAgeVals = X[numpy.isnan(X.Age)]\n",
    "    datasetMissingAgeVals = datasetMissingAgeVals.drop([\"Age\"], axis=1)\n",
    "\n",
    "    #from sklearn.ensemble import RandomForestRegressor\n",
    "    #ageClassifier= RandomForestRegressor(n_estimators=2000, random_state=314)\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    ageClassifier = GradientBoostingRegressor()\n",
    "    ageClassifier.fit(ageDataset, ageTarget.astype(int))\n",
    "    guessedAges = ageClassifier.predict(datasetMissingAgeVals)\n",
    "\n",
    "    counter=0\n",
    "    for row in xrange(0,len(X.Age)):\n",
    "        if numpy.isnan(X.Age[row]):\n",
    "            X.Age[row]=guessedAges[counter]\n",
    "            counter+=1\n",
    "    return X\n",
    "\n",
    "def dropAge(X):\n",
    "    return X.drop([\"Age\"], axis=1)\n",
    "\n",
    "def binAge(X): #Handles Age by first getting the values filled then binning into categories Child, Adult, and Elderly\n",
    "    X = handleAge(X)\n",
    "    from collections import defaultdict\n",
    "    triBins = defaultdict(str)\n",
    "    for i in xrange(len(X.Age)):\n",
    "        if X.Age.iloc[i]<16:\n",
    "            triBins[i]=\"Child\"\n",
    "        elif X.Age.iloc[i]<55:\n",
    "            triBins[i]=\"Adult\"\n",
    "        else:\n",
    "            triBins[i]=\"Elderly\"\n",
    "    X = pd.concat([X, pd.get_dummies(triBins)], axis=1)\n",
    "    X = X.drop([\"Child\"], axis=1)\n",
    "    X = X.drop([\"Age\"], axis=1)\n",
    "    return X\n",
    "\n",
    "def meanAge(X): #Imputes missing values of Age with the mean\n",
    "    X.Age = X.Age.fillna(X.Age.mean())\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here I considered trying some arithmetic transformations, but it didn't look like they ended up being useful.\n",
    "\n",
    "#Create some new features with basic arithmetic operations\n",
    "def deriveNewColumns(X):\n",
    "    newdataset = X.copy()\n",
    "    for x1 in xrange(0, len(X.columns)):\n",
    "        for x2 in xrange(x1+1, len(X.columns)):\n",
    "            col1name = X.columns[x1]\n",
    "            col2name = X.columns[x2]\n",
    "            #print col1name, col2name\n",
    "            newAddDF = pd.DataFrame(X[col1name]+X[col2name], columns = [str(col1name)+\"+\"+str(col2name)])\n",
    "            newSubDF = pd.DataFrame(X[col1name]-X[col2name], columns = [str(col1name)+\"-\"+str(col2name)])\n",
    "            newMulDF = pd.DataFrame(X[col1name]*X[col2name], columns = [str(col1name)+\"*\"+str(col2name)])\n",
    "            #newDivDF -- don't want to deal with div by zero \n",
    "            newdataset = pd.concat([newdataset, newAddDF, newSubDF, newMulDF], axis=1)\n",
    "            #newdataset = pd.concat([newdataset, newAddDF], axis=1)\n",
    "    return newdataset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanicDataset = pd.read_csv(\"train.csv\")\n",
    "X = titanicDataset.drop([\"Survived\"], axis=1)\n",
    "y = titanicDataset.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
       "count   891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean    446.000000    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std     257.353842    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min       1.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%     223.500000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%     446.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%     668.500000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max     891.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Graham, Mr. George Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "describe_categorical(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Izzy\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Izzy\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Process data here\n",
    "#The variables presented to the model are altered by the processing done here.\n",
    "\n",
    "#X = dropPassengerId(X)\n",
    "\n",
    "#X = addFamily(X)\n",
    "\n",
    "X = handlePclass(X)\n",
    "#X = dropPclass(X)\n",
    "\n",
    "X = handleName(X)\n",
    "#X = dropName(X)\n",
    "\n",
    "X = handleSex(X)\n",
    "#X = dropSex(X)\n",
    "\n",
    "X = handleSibSp(X)\n",
    "#X = dropSibSp(X)\n",
    "\n",
    "X = handleParch(X)\n",
    "#X = dropParch(X)\n",
    "\n",
    "X = handleTicket(X)\n",
    "#X = dropTicket(X)\n",
    "\n",
    "X = handleCabin(X)\n",
    "#X = dropCabin(X)\n",
    "\n",
    "X = handleEmbarked(X)\n",
    "#X = dropEmbarked(X)\n",
    "\n",
    "X = handleFareBasic(X)\n",
    "#X = handleFareAdvanced(X) #This doesn't seem to help. Modeled on how we're handling age\n",
    "#X = binFare(X)\n",
    "#X = logFare(X)\n",
    "#X = dropFare(X)\n",
    "\n",
    "X = handleAge(X)  # Do this last because of the way we're imputing Age\n",
    "#X = binAge(X)\n",
    "#X = meanAge(X)\n",
    "#X = dropAge(X)\n",
    "\n",
    "#X = deriveNewColumns(X) # This just appears to add variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>CrewMember</th>\n",
       "      <th>Master.</th>\n",
       "      <th>Miss.</th>\n",
       "      <th>...</th>\n",
       "      <th>CabinLetters_C</th>\n",
       "      <th>CabinLetters_D</th>\n",
       "      <th>CabinLetters_E</th>\n",
       "      <th>CabinLetters_F</th>\n",
       "      <th>CabinLetters_G</th>\n",
       "      <th>CabinLetters_None</th>\n",
       "      <th>CabinLetters_T</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.352413</td>\n",
       "      <td>29.654892</td>\n",
       "      <td>32.746366</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.206510</td>\n",
       "      <td>0.551066</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.044893</td>\n",
       "      <td>0.206510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066218</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.035915</td>\n",
       "      <td>0.014590</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>0.771044</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.188552</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.722783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>13.588875</td>\n",
       "      <td>49.514272</td>\n",
       "      <td>0.428790</td>\n",
       "      <td>0.405028</td>\n",
       "      <td>0.497665</td>\n",
       "      <td>0.140770</td>\n",
       "      <td>0.207186</td>\n",
       "      <td>0.405028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248802</td>\n",
       "      <td>0.188959</td>\n",
       "      <td>0.186182</td>\n",
       "      <td>0.119973</td>\n",
       "      <td>0.066890</td>\n",
       "      <td>0.420397</td>\n",
       "      <td>0.033501</td>\n",
       "      <td>0.391372</td>\n",
       "      <td>0.281141</td>\n",
       "      <td>0.447876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>4.012500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>7.925000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.613707</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId         Sex         Age        Fare           1  \\\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean    446.000000    0.352413   29.654892   32.746366    0.242424   \n",
       "std     257.353842    0.477990   13.588875   49.514272    0.428790   \n",
       "min       1.000000    0.000000    0.420000    4.012500    0.000000   \n",
       "25%     223.500000    0.000000   21.000000    7.925000    0.000000   \n",
       "50%     446.000000    0.000000   28.613707   15.100000    0.000000   \n",
       "75%     668.500000    1.000000   37.000000   32.204208    0.000000   \n",
       "max     891.000000    1.000000   80.000000  512.329200    1.000000   \n",
       "\n",
       "                2           3  CrewMember     Master.       Miss.     ...      \\\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000     ...       \n",
       "mean     0.206510    0.551066    0.020202    0.044893    0.206510     ...       \n",
       "std      0.405028    0.497665    0.140770    0.207186    0.405028     ...       \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000     ...       \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000     ...       \n",
       "50%      0.000000    1.000000    0.000000    0.000000    0.000000     ...       \n",
       "75%      0.000000    1.000000    0.000000    0.000000    0.000000     ...       \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000     ...       \n",
       "\n",
       "       CabinLetters_C  CabinLetters_D  CabinLetters_E  CabinLetters_F  \\\n",
       "count      891.000000      891.000000      891.000000      891.000000   \n",
       "mean         0.066218        0.037037        0.035915        0.014590   \n",
       "std          0.248802        0.188959        0.186182        0.119973   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          0.000000        0.000000        0.000000        0.000000   \n",
       "50%          0.000000        0.000000        0.000000        0.000000   \n",
       "75%          0.000000        0.000000        0.000000        0.000000   \n",
       "max          1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "       CabinLetters_G  CabinLetters_None  CabinLetters_T           C  \\\n",
       "count      891.000000         891.000000      891.000000  891.000000   \n",
       "mean         0.004489           0.771044        0.001122    0.188552   \n",
       "std          0.066890           0.420397        0.033501    0.391372   \n",
       "min          0.000000           0.000000        0.000000    0.000000   \n",
       "25%          0.000000           1.000000        0.000000    0.000000   \n",
       "50%          0.000000           1.000000        0.000000    0.000000   \n",
       "75%          0.000000           1.000000        0.000000    0.000000   \n",
       "max          1.000000           1.000000        1.000000    1.000000   \n",
       "\n",
       "                Q           S  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.086420    0.722783  \n",
       "std      0.281141    0.447876  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    0.000000  \n",
       "50%      0.000000    1.000000  \n",
       "75%      0.000000    1.000000  \n",
       "max      1.000000    1.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Scale the set\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch on Hyperparameters for Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The following commented code is adapted directly from lecture entitled Random Forests == Awesome\n",
    "#Remove # as necessary to search different combinations of parameters\n",
    "\n",
    "#from sklearn.ensemble import GradientBoostingRegressor\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "##n_estimator_options = [200, 500, 1000, 1500, 2000]\n",
    "##n_estimator_options = [100,200,300,400,500]\n",
    "##n_estimator_options = [80,90,100,110,120,130,140, 200]\n",
    "#n_estimator_options=[100]\n",
    "##max_features_options = [\"auto\", None, \"sqrt\", \"log2\", 0.9, 0.2]\n",
    "#max_features_options = [\"log2\"]\n",
    "##min_samples_leaf_options = [1, 2, 3, 4, 5]\n",
    "##min_samples_leaf_options = [3,4,5,6,7,8]\n",
    "#min_samples_leaf_options=[8]\n",
    "##min_samples_split_options = [1,2,3,4,5]\n",
    "#min_samples_split_options = [1]\n",
    "##max_depth_options = [1,2,3,4,5,6,7,8,9,10]\n",
    "#max_depth_options = [4]\n",
    "#max_leaf_nodes_options = [2,3,4,5, None]\n",
    "#min_weight_fraction_leaf_options = [0.0,0.1,0.2,0.3,0.4]\n",
    "\n",
    "#gbModel = GradientBoostingRegressor()\n",
    "#estimator = GridSearchCV(gbModel, dict(\n",
    "#        n_estimators=n_estimator_options,\n",
    "#        max_features=max_features_options,\n",
    "#        min_samples_leaf=min_samples_leaf_options,\n",
    "#        min_samples_split=min_samples_split_options,\n",
    "#        max_depth=max_depth_options,\n",
    "#        max_leaf_nodes = max_leaf_nodes_options,\n",
    "#        min_weight_fraction_leaf = min_weight_fraction_leaf_options\n",
    "#    ), cv=3, n_jobs=-2, scoring=\"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#estimator.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#estimator.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gbModel = estimator.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, init=None, learning_rate=0.1, loss='ls',\n",
       "             max_depth=4, max_features='log2', max_leaf_nodes=None,\n",
       "             min_samples_leaf=8, min_samples_split=1,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "             presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make train and test datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#These hyperparameters were picked by the above gridsearch\n",
    "gbModel = GradientBoostingRegressor(n_estimators=100, \n",
    "                                    max_depth=4,\n",
    "                                    max_features=\"log2\", \n",
    "                                    max_leaf_nodes=None,\n",
    "                                    min_samples_leaf=8, \n",
    "                                    min_samples_split=1, \n",
    "                                    min_weight_fraction_leaf=0.0,\n",
    "                                    random_state=42)\n",
    "gbModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86475616  0.83876812  0.82994652  0.87045455  0.91346154  0.90186404\n",
      "  0.87282051  0.9025974   0.95028249  0.875     ]\n",
      "[ 0.15021344  0.12098253  0.15875597  0.12391353  0.10942583  0.12129104\n",
      "  0.1341797   0.12474921  0.09178329  0.12207822]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "rocScores = cross_val_score(gbModel, X, y, cv=10, scoring=\"roc_auc\", n_jobs=-2)\n",
    "mseScores = cross_val_score(gbModel, X, y, cv=10, scoring=\"mean_squared_error\", n_jobs=-2) #These return negative by convention per docs.\n",
    "mseScores*=-1\n",
    "print rocScores\n",
    "print mseScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC:  0.881995131918  +-  0.0243767939732\n",
      "MSE:      0.125737275878  +-  0.0128747261386\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import sem\n",
    "print \"ROC AUC: \",rocScores.mean(),\" +- \", 2.262*sem(rocScores, ddof=0) #Mean ROC AUC and 95% ci\n",
    "print \"MSE:     \",mseScores.mean(),\" +- \", 2.262*sem(mseScores, ddof=0) #Mean MSE and 95% ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
